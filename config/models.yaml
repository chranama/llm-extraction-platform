# config/models.yaml
# ------------------------------------------------------------
# Shape:
#   base:      canonical defaults for all environments
#   profiles:  overlays applied on top of base (selected by MODELS_PROFILE,
#              fallback APP_PROFILE, default host)
#
# Selection:
#   MODELS_PROFILE=host|docker-portable|docker|test|...
#   fallback: APP_PROFILE
#   default: host
#
# Semantics:
# - base is generate-only and CPU-friendly
# - overlay profiles PATCH models by id (merge-by-id)
# - test profile replaces catalog with a fake model
# ------------------------------------------------------------

base:
  # ----------------------------------------------------------
  # HOST / DEV DEFAULT (generate-only, CPU-friendly)
  # ----------------------------------------------------------
  default_model: meta-llama/Llama-3.2-1B-Instruct

  defaults:
    backend: local
    load_mode: lazy
    device: auto
    trust_remote_code: false
    quantization: null
    capabilities:
      generate: true
      extract: false

  models:
    - id: meta-llama/Llama-3.2-1B-Instruct
      dtype: float16
      text_only: true
      max_context: 4096
      capabilities:
        generate: true
        extract: false
      notes: "Base default (small, CPU-friendly; generate-only)"

    - id: mistralai/Mistral-7B-Instruct-v0.3
      dtype: float16
      text_only: true
      max_context: 8192
      capabilities:
        generate: true
        extract: false
      notes: "Optional model (generate-only)"

    - id: Qwen/Qwen2.5-7B-Instruct
      dtype: float16
      text_only: true
      max_context: 8192
      capabilities:
        generate: true
        extract: false
      notes: "Optional model (generate-only)"

    - id: mistralai/Ministral-3-14B-Instruct-2512-BF16
      dtype: bfloat16
      text_only: false
      max_context: 32768
      trust_remote_code: true
      capabilities:
        generate: true
        extract: false
      notes: "Large model (not portable; only enable intentionally)"


profiles:
  # ----------------------------------------------------------
  # HOST (explicit no-op; base applies)
  # ----------------------------------------------------------
  host: {}

  # ----------------------------------------------------------
  # DOCKER / PORTABLE (ROOT-CAUSE FIX)
  #
  # Goal: do NOT accidentally pull a huge model in docker CPU mode.
  # - keep generate-only
  # - keep lazy load
  # - choose a small primary model
  # ----------------------------------------------------------
  docker-portable:
    default_model: meta-llama/Llama-3.2-1B-Instruct

    defaults:
      backend: local
      load_mode: lazy
      device: auto
      trust_remote_code: false
      quantization: null
      capabilities:
        generate: true
        extract: false

    models:
      - id: meta-llama/Llama-3.2-1B-Instruct
        load_mode: lazy
        capabilities:
          generate: true
          extract: false
        notes: "Docker portable default (avoid big pulls)"

  # ----------------------------------------------------------
  # DOCKER / FULL CATALOG (INTENTIONAL)
  #
  # Uses merge-by-id semantics:
  # - Does NOT redefine entire models list
  # - Only patches models that differ from base
  # ----------------------------------------------------------
  docker:
    default_model: mistralai/Ministral-3-14B-Instruct-2512-BF16

    models:
      # Enable extract + eager load for primary model
      - id: mistralai/Ministral-3-14B-Instruct-2512-BF16
        load_mode: eager
        capabilities:
          generate: true
          extract: true
        notes: "Primary docker model (extract enabled; heavy)"

      # Add heavier peer model (new model â†’ appended)
      - id: Qwen/Qwen2.5-14B-Instruct
        dtype: bfloat16
        text_only: true
        max_context: 32768
        capabilities:
          generate: true
          extract: false
        notes: "Peer 14B text-only model (docker; heavy)"

  # ----------------------------------------------------------
  # TEST (integration tests)
  #
  # Fully overrides catalog with fake model
  # ----------------------------------------------------------
  test:
    default_model: fake

    defaults:
      backend: local
      load_mode: lazy
      device: auto
      trust_remote_code: false
      quantization: null
      capabilities:
        generate: true
        extract: true

    models:
      - id: fake
        load_mode: lazy
        capabilities:
          generate: true
          extract: true
        notes: "Fake model for integration tests"