service:
  name: "LLM Server (test)"
  version: "0.1.0"
  debug: false
  env: "test"

server:
  host: "127.0.0.1"
  port: 8000

api:
  cors_allowed_origins:
    - "*"

model:
  # tests patch the LLM builder anyway; keep this benign
  default_id: "fake"
  allowed_models: []
  models_config_path: "config/models.yaml"
  dtype: "float16"
  device: "cpu"

redis:
  enabled: false

http:
  llm_service_url: "http://127.0.0.1:9001"
  client_timeout_seconds: 5

limits:
  rate_limit_rpm:
    admin: 0
    default: 120
    free: 30
  quota_auto_reset_days: 30

cache:
  api_key_cache_ttl_seconds: 1