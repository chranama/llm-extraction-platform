[project]
name = "llm_server"
version = "1.0.0"
requires-python = "==3.12.*"
dependencies = [
  # --- API / web ---
  "fastapi>=0.116",
  "uvicorn[standard]>=0.35",

  # --- LLM runtime ---
  "transformers==5.0.0rc0",
  "accelerate>=1.0.0",
  "mistral-common>=1.8.6",
  "safetensors>=0.4.0",

  # --- config / serialization ---
  "python-dotenv>=1.0.0",
  "pydantic-settings>=2.0",
  "orjson>=3.9.15",

  # --- observability ---
  "prometheus-client>=0.20",

  # --- persistence / migrations ---
  "sqlalchemy>=2.0",
  "greenlet>=3.0",
  "alembic>=1.16.4",
  "asyncpg>=0.29",
  "aiosqlite>=0.20",

  # --- caching / http ---
  "redis>=5.0",
  "httpx>=0.27",

  # --- phase 0 memory guard ---
  "psutil>=5.9,<6.0",

  # --- misc ---
  "typing-extensions>=4.8",
  "jsonschema>=4.21,<5.0",
  "typer>=0.12",
  "llm-contracts",

  # âœ… default torch = CPU baseline (also fine on macOS; MPS is runtime)
  "torch>=2.4",
  "torchvision>=0.19",
  "torchaudio>=2.4",
]

[project.optional-dependencies]
cuda121 = [
  "torch>=2.4",
  "torchvision>=0.19",
  "torchaudio>=2.4",
]

test = [
  "pytest>=8",
  "httpx>=0.27",
  "asgi-lifespan>=2.1",
  "pytest-cov>=5",
  "coverage>=7",
]

lint = [
  "ruff>=0.5",
  "black>=24",
]

[project.scripts]
llm = "llm_server.cli:main"

# ---------- uv configuration ----------

[tool.uv.sources]
# Default-safe path: CPU wheels for deterministic local/CI resolution.
# This keeps `uv sync` stable without requiring CUDA-specific indexes.
torch = [
  { index = "pytorch-cpu" },
]
torchvision = [
  { index = "pytorch-cpu" },
]
torchaudio = [
  { index = "pytorch-cpu" },
]
llm-contracts = { path = "../contracts", editable = true }

# CUDA scaffold (opt-in):
# If you want CUDA 12.1 wheels, switch the three source entries above to:
#
# torch = [
#   { index = "pytorch-cu121" },
# ]
# torchvision = [
#   { index = "pytorch-cu121" },
# ]
# torchaudio = [
#   { index = "pytorch-cu121" },
# ]
#
# Then sync with:
#   uv sync --extra cuda121
# Keep this opt-in to avoid CPU/CUDA mixed-index resolver conflicts in default flows.

[tool.uv]
package = true
prerelease = "allow"

dev-dependencies = [
  "pytest>=8",
  "asgi-lifespan>=2.1",
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu121"
url = "https://download.pytorch.org/whl/cu121"
explicit = true

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["src"]
include = ["llm_server*"]
exclude = ["tests*", "scripts*", "data*", "notebooks*"]

[tool.setuptools.package-data]
llm_server = ["schemas/*.json"]
